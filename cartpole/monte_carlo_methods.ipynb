{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Generally speaking Monte Carlo control is characterised by approximating the value function of state action pairs by using sample approximations for their rewards.\n",
    "\n",
    "In particular the Monte Carlo approach doesn't bootstrap the value function but instead observes a full episode before "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the value function\n",
    "\n",
    "A psuedo algorithm for learning the value function using monte carlo methods is roughly;  \n",
    "\n",
    "- Initialise\n",
    "- while episode running:\n",
    "    - take a step using policy and observe S0\n",
    "    - for each step:\n",
    "        - rewards = gamma*rewards + return\n",
    "        - append state_history {state: rewards}\n",
    "        - value[state] = mean(state_history[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key nugget here is that the monte carlo approach can only reflect on the merits of its decisions once an episode has finished and the states observed. Unless of course the agent visits a single state more than once within the same episode.\n",
    "\n",
    "There are some merits to updating the value function as often as possible when running many agents concurrently in async while updating the same value functions.\n",
    "\n",
    "Key traits:  \n",
    "- the value function is not used when estimating improvements, we only average past experience  \n",
    "- mostly assumes the statespace is of reasonable size and discrete (as it actively stores state values, atleast in its simplest form)  \n",
    "\n",
    "To apply this to problems such as the pole cart we need to discretize the state space. This can be reasonable done for such a simple 4 value state space of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_space(obs: np.array):\n",
    "    return np.round(obs,decimals=3)\n",
    "\n",
    "class "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
