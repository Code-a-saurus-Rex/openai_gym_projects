{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Gym is a python package we can use to programatically interact with existing reinforcement learning environments.  \n",
    "Freeing up time and effort to focus on algorithms and research.\n",
    "\n",
    "### Instantiating an environment\n",
    "\n",
    "Let's start by creating the cartpole environment; a scenario where we have control of a cart balancing a pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f8d14459d60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "import numpy\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple game we have 2 possible actions; moving the cart left or right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate the environment taking random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env = gym.make(\"CartPole-v1\",render_mode=\"human\")\n",
    "env = gym.make(\"CartPole-v1\",render_mode='rgb_array')\n",
    "\n",
    "\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "for _ in range(30):\n",
    "    img = plt.imshow(env.render())\n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    # plt.show()   \n",
    "    action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break it down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we render the environment if we have an output device setup (using say Xming) using;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can close this output again when we call the `close` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example we are rendering inside this notebook for ease of use. This is actually quite slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the environment\n",
    "\n",
    "We interact with the environment by taking a `step` in time. We continue to step until our game ends or terminates, usually called an `episode`.\n",
    "\n",
    "A step returns a tuple of 4 objects;  \n",
    "\n",
    "- Observation (object)  \n",
    "- reward (float)  \n",
    "- done (bool)  \n",
    "- info (dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting observation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0406924 ,  0.01500509,  0.02519564, -0.03433322])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to take a step we must specify an action.  \n",
    "Since our action space has 2 options we know that our actions can be either [0,1] index;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, reward, done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04099251, -0.18046894,  0.02450898,  0.2661915 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our observation array has indeed changed due to our action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the action space provided by Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the observation space provided by Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
